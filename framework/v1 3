# Framework AIAD v1.3
*AI-Agent Iterative Development*

**La m√©thodologie de r√©f√©rence pour le d√©veloppement produit √† l'√®re des agents IA**

Version 1.3 - Janvier 2026

---

## Table des mati√®res

1. [Pr√©ambule : Le Changement de Paradigme](#pr√©ambule)
2. [Vision et Philosophie AIAD](#vision-et-philosophie)
3. [L'√âcosyst√®me AIAD](#l√©cosyst√®me-aiad)
4. [Les Artefacts Vivants](#les-artefacts-vivants)
5. [Les Boucles It√©ratives Continues](#les-boucles-it√©ratives-continues)
6. [Synchronisations Intentionnelles](#synchronisations-intentionnelles)
7. [M√©triques et Am√©lioration Continue](#m√©triques-et-am√©lioration-continue)
8. [Annexes](#annexes)

---

# Pr√©ambule : Le Changement de Paradigme

## De l'Artisan au Chef d'Orchestre

Pendant des d√©cennies, le d√©veloppement logiciel a √©t√© l'apanage d'artisans techniques ma√Ætrisant syntaxe, patterns et architectures. **Cette √©poque est r√©volue.**

Les agents IA ne sont pas de simples outils d'autocompl√©tion. Ce sont des **partenaires de d√©veloppement autonomes** capables de transformer une intention en code fonctionnel, de g√©n√©rer des tests, de d√©tecter des vuln√©rabilit√©s, et d'optimiser des performances.

Le d√©veloppeur moderne n'est plus celui qui code le mieux, mais **celui qui orchestre le mieux**.

## Les Trois V√©rit√©s d'AIAD

### 1. La valeur √©merge de l'intention, pas de l'ex√©cution

**Ce qui compte :**
- Clart√© du probl√®me √† r√©soudre
- Qualit√© des sp√©cifications
- Validation des outcomes

**Ce qui compte moins :**
- Lignes de code √©crites
- Ma√Ætrise syntaxique
- V√©locit√© brute

### 2. La complexit√© se g√®re par l'observation, pas par la planification

Dans un monde d'√©mergence, les pr√©dictions sont des illusions. Seule la boucle rapide "essayer ‚Üí observer ‚Üí adapter" g√©n√®re de la certitude.

### 3. L'excellence vient de l'√©cosyst√®me, pas de l'individu

Un Product Engineer m√©diocre avec d'excellents agents surpasse un d√©veloppeur brillant seul. Construire et optimiser l'√©cosyst√®me d'agents est l'investissement √† plus haut ROI.

## Pourquoi AIAD v1.3 ?

La v1.2 a radicalis√© la rupture avec Scrum et syst√©matis√© l'approche empirique. La v1.3 va √† l'essentiel :

- **Framework conceptuel clair** : Focus sur les principes et la structure
- **Pragmatisme maximal** : D√©tails d'impl√©mentation en annexes
- **Adoptabilit√© rapide** : Comprendre AIAD en 30 minutes, le ma√Ætriser en 3 mois

---

# Vision et Philosophie AIAD

## Principe Cardinal : La Valeur Avant Tout

AIAD ne juge pas sur l'effort, la v√©locit√© ou la conformit√© aux processus. **AIAD juge sur la valeur r√©alis√©e pour les stakeholders.**

- Une fonctionnalit√© non utilis√©e est un √©chec, quelle que soit sa qualit√© technique
- Une fonctionnalit√© qui r√©sout un faux probl√®me est un √©chec, quelle que soit la rapidit√© de livraison
- Une fonctionnalit√© qui cr√©e plus de probl√®mes qu'elle n'en r√©sout est un √©chec, quelles que soient les m√©triques interm√©diaires

## Les Quatre Piliers d'AIAD

### 1. Empirisme Radical

**Principes :**
- **Hypoth√®ses > Certitudes** : Tout est une hypoth√®se jusqu'√† preuve du contraire
- **Observation > Opinion** : Les donn√©es et les usages r√©els priment sur les intuitions
- **Adaptation > Adh√©rence** : Pivoter rapidement vaut mieux que pers√©v√©rer dans l'erreur
- **Apprentissage > Ex√©cution** : Maximiser la vitesse d'apprentissage, pas la vitesse de production

### 2. Orchestration Syst√©mique

**Principes :**
- Les humains d√©finissent le "pourquoi" et le "quoi", les agents IA g√©n√®rent le "comment"
- L'excellence vient de la qualit√© de l'√©cosyst√®me d'agents, pas de l'h√©ro√Øsme individuel
- La dette la plus co√ªteuse est la dette de contexte (agents mal configur√©s, documentation obsol√®te)
- L'am√©lioration continue de l'orchestration est plus importante que l'am√©lioration du code

### 3. Fluidit√© par √âmergence

**Principes :**
- Pas de cadence artificielle (Sprints), mais un flux continu ajust√© √† la complexit√© r√©elle
- Pas de c√©r√©monies prescrites, mais des synchronisations intentionnelles quand n√©cessaires
- Pas de r√¥les rigides, mais des responsabilit√©s fluides adapt√©es au contexte
- Pas de planification d√©taill√©e long-terme, mais une direction claire et des ajustements continus

### 4. Excellence Produit

**Principes :**
- **Product thinking > Project thinking** : Focus sur le cycle de vie complet, pas sur la livraison
- **Discovery int√©gr√©e** : Comprendre le probl√®me fait partie du d√©veloppement, pas une phase s√©par√©e
- **Qualit√© built-in** : La qualit√© est non n√©gociable, pas un trade-off
- **Validation continue** : La release n'est pas la fin, c'est le d√©but de l'apprentissage

## Le Manifeste AIAD

**Nous valorisons :**

- **Outcomes observables** plut√¥t que outputs livr√©s
- **Intention claire** plut√¥t que sp√©cifications exhaustives
- **Observation empirique** plut√¥t que planification d√©taill√©e
- **Orchestration ma√Ætris√©e** plut√¥t que codage h√©ro√Øque
- **Am√©lioration continue** plut√¥t que conformit√© aux processus
- **Collaboration intentionnelle** plut√¥t que r√©unions prescrites
- **Responsabilit√© partag√©e** plut√¥t que silos fonctionnels
- **Excellence long-terme** plut√¥t que livraison √† tout prix

Sans ignorer les √©l√©ments de droite, nous reconnaissons que les √©l√©ments de gauche cr√©ent plus de valeur dans un contexte de d√©veloppement assist√© par agents IA.

---

# L'√âcosyst√®me AIAD

## Principe Fondamental : Responsabilit√©s, pas R√¥les

Dans AIAD, il n'y a pas de "r√¥les" au sens traditionnel, mais des **responsabilit√©s** qui doivent √™tre assum√©es. Une personne peut porter plusieurs responsabilit√©s. Une responsabilit√© peut √™tre partag√©e entre plusieurs personnes. L'important est la clart√© sur qui assume quoi.

## Les Responsabilit√©s Cl√©s

### Product Manager (PM) - Responsable de la Valeur

**Essence :** Maximiser la valeur long-terme en √©quilibrant vision, r√©alit√© march√©, et capacit√©s de l'√©quipe.

**Le PM dans AIAD EST :**
- Un leader produit avec vision strat√©gique claire
- Un expert en d√©couverte de probl√®mes et validation d'hypoth√®ses
- Un arbitre de trade-offs complexes
- Un obs√©d√© de la mesure d'impact r√©el

**Comp√©tences critiques (non n√©gociables) :**
1. **Product Strategy** : Vision inspirante et actionnable, positionnement diff√©renciant
2. **Discovery & Research** : Entretiens utilisateurs, analyse quali/quanti, identification du vrai probl√®me
3. **Product Analytics** : D√©finition de m√©triques pertinentes, analyse comportementale, d√©cisions data-informed
4. **Outcome-Oriented Thinking** : Focus probl√®mes r√©solus vs. fonctionnalit√©s livr√©es
5. **Trade-off Mastery** : Arbitrage court/long-terme, gestion de stakeholders contradictoires

**Responsabilit√©s concr√®tes :**
- D√©finir et communiquer le **Product Goal** (horizon 4-12 semaines)
- Maintenir un **Product Backlog** ordonn√© par valeur r√©elle
- D√©finir les **Outcome Criteria** pour chaque fonctionnalit√© majeure
- Conduire la **Discovery** (probl√®me, solution, validation)
- Mesurer l'**impact r√©el** des releases
- Arbitrer les **trade-offs**
- Engager et aligner les **stakeholders**

**Indicateurs de succ√®s :**
- % de fonctionnalit√©s atteignant leurs Outcome Criteria : >70%
- Temps entre insight et release : <2 semaines
- Satisfaction stakeholders : >8/10
- ROI mesur√© des fonctionnalit√©s majeures

> üìñ *Voir Annexe B.1 pour les anti-patterns √† √©viter et exemples d√©taill√©s*

---

### Product Engineer (PE) - Responsable de l'Orchestration

**Essence :** Transformer des intentions en r√©alit√© technique de qualit√© en orchestrant un √©cosyst√®me d'agents IA.

**Le PE dans AIAD EST :**
- Un orchestrateur d'agents IA
- Un architecte de solutions orient√© outcomes
- Un validateur de qualit√© multi-dimensionnelle
- Un contributeur actif √† la discovery

**Comp√©tences critiques :**
1. **Orchestration d'Agents IA** : Formulation d'intentions claires, structuration du contexte, it√©ration sur prompts
2. **Architecture & Design** : Pens√©e syst√©mique, anticipation des implications techniques
3. **Quality Thinking** : D√©finition de "Done", pens√©e cas limites, √©quilibre tests/pragmatisme
4. **Product Thinking** : Compr√©hension contexte m√©tier, questionnement des specs
5. **D√©composition de Complexit√©** : Division en t√¢ches atomiques, identification des risques

**Responsabilit√©s concr√®tes :**
- Orchestrer les agents IA pour g√©n√©rer du code de qualit√©
- R√©diger les SPECs techniques d√©taill√©es
- Valider la qualit√© du code g√©n√©r√©
- Maintenir le contexte (AGENT-GUIDE, learnings, patterns)
- Collaborer √† la discovery (prototypes, faisabilit√©)
- G√©rer la dette technique (transparence et rem√©diation)

**Indicateurs de succ√®s :**
- First-time success rate : >70%
- Ratio code g√©n√©r√© / code manuel : >80/20
- Couverture de tests : >80% backend, >70% frontend
- Temps moyen par fonctionnalit√© : tendance d√©croissante

> üìñ *Voir Annexe B.2 pour le workflow quotidien type et anti-patterns*

---

### Agents Engineer (AE) - Responsable de l'√âcosyst√®me IA

**Essence :** Construire, optimiser et maintenir l'√©cosyst√®me d'agents IA qui d√©multiplie les capacit√©s de l'√©quipe.

**Vision :** L'Agents Engineer ne g√®re pas des outils, il construit un **√©cosyst√®me d'intelligence augment√©e**. C'est l'investissement √† plus haut ROI de l'√©quipe.

**Comp√©tences critiques :**
1. **IA Engineering** : LLMs (capacit√©s/limites), prompt engineering avanc√©, fine-tuning contextuel
2. **Systems Thinking** : Vision holistique, optimisation globale vs. locale
3. **Broad Technical Knowledge** : Compr√©hension cross-domain (s√©curit√©, qualit√©, architecture, DevOps)
4. **Data-Driven Optimization** : Mesure performance agents, A/B testing configurations

**Responsabilit√©s concr√®tes :**
- S√©lectionner les agents sp√©cialis√©s pertinents
- Configurer et calibrer chaque agent
- D√©finir la gouvernance (niveaux de supervision, r√®gles de validation)
- Former l'√©quipe √† l'utilisation efficace
- Monitorer les performances des agents
- Optimiser continuellement l'√©cosyst√®me
- Exp√©rimenter avec nouveaux agents

**L'√©cosyst√®me d'agents : approche stratifi√©e**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Agents de Gouvernance (Tier 1)               ‚îÇ
‚îÇ        Security, Compliance, Architecture           ‚îÇ
‚îÇ        ‚Üí Droit de veto                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Agents de Qualit√© (Tier 2)                   ‚îÇ
‚îÇ        Quality (tests), Code Review, Performance    ‚îÇ
‚îÇ        ‚Üí Avertissements                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Agents de Productivit√© (Tier 3)              ‚îÇ
‚îÇ        Documentation, Refactoring, Migration        ‚îÇ
‚îÇ        ‚Üí Suggestions                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Agent Principal de D√©veloppement (Core)      ‚îÇ
‚îÇ        Claude Code / Cursor / Copilot               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Principe de s√©lection d'agents :**
1. Commencer minimal : Agent principal + Agent Security + Agent Quality
2. Ajouter par douleur : Quand un probl√®me r√©current √©merge
3. Retirer par obsolescence : Si un agent n'est plus utilis√©
4. Optimiser par mesure : Suivre usage et efficacit√©

**Indicateurs de succ√®s :**
- Taux d'adoption des agents : >90%
- Taux de faux positifs : <20%
- Temps r√©solution probl√®mes agents : <2h
- Satisfaction PE sur √©cosyst√®me : >8/10

> üìñ *Voir Annexe F pour le catalogue complet des agents sp√©cialis√©s*

---

### QA Engineer - Responsable de la Qualit√© Multi-Dimensionnelle

**Essence :** Garantir que la qualit√© est built-in, pas bolt-on.

Le QA dans AIAD n'est pas un "testeur" qui v√©rifie √† la fin. C'est un **architecte de qualit√©** qui d√©finit les standards, co-cr√©e les strat√©gies de test avec les agents, et valide la qualit√© multi-dimensionnelle.

**Comp√©tences critiques :**
1. **Test Strategy Design** : Strat√©gie adapt√©e √† chaque type de fonctionnalit√©
2. **Quality Thinking** : Penser au-del√† des happy paths, identifier cas limites
3. **Collaboration avec Agents** : Calibrer Agent Quality, valider pertinence des tests g√©n√©r√©s
4. **User Empathy** : Tester l'utilisabilit√©, pas juste la fonctionnalit√©

**Responsabilit√©s concr√®tes :**
- D√©finir la strat√©gie de tests globale
- Contribuer au Definition of Output Done
- Valider la pertinence des tests g√©n√©r√©s par les agents
- Conduire les tests exploratoires
- Identifier et documenter bugs et r√©gressions
- Mesurer et communiquer la qualit√© r√©elle

**Les 4 niveaux de validation :**

| Niveau | Responsable | Type | Automatisation | Quand |
|--------|-------------|------|----------------|-------|
| Unitaire | Agents IA + PE | Tests unitaires | 100% | Post-g√©n√©ration |
| Int√©gration | PE + Agent Quality | Tests d'int√©gration | 90% | Pr√©-commit |
| Fonctionnel | QA + Agent Quality | Tests de sc√©narios | 70% | Pr√©-merge |
| Exploratoire | QA | Tests manuels cibl√©s | 0% | Pr√©-release |

**Indicateurs de succ√®s :**
- Couverture de tests : >80% backend, >70% frontend
- Bugs en production : tendance d√©croissante (-20% /trimestre)
- Temps d√©tection bug : <24h
- Taux de r√©gression : <5%

> üìñ *Voir Annexe B.3 pour les strat√©gies de test d√©taill√©es*

---

### Tech Lead - Responsable de la Coh√©rence Technique

**Essence :** Garantir que les d√©cisions techniques s'alignent avec la vision long-terme et cr√©ent une base solide pour l'√©volution du produit.

Le Tech Lead n'est pas un "super d√©veloppeur". C'est un **architecte de syst√®mes √©volutifs** et un **coach technique**.

**Comp√©tences critiques :**
1. **Systems Architecture** : Vision holistique, anticipation des √©volutions futures
2. **Technical Leadership** : Coaching, mentorat, facilitation de d√©cisions complexes
3. **Strategic Technical Thinking** : Alignement technique et strat√©gie produit, gestion dette technique

**Responsabilit√©s concr√®tes :**
- D√©finir et maintenir le document ARCHITECTURE
- Valider les d√©cisions architecturales majeures
- Conduire les revues techniques (design reviews)
- √âtablir les standards de qualit√© et conventions
- G√©rer la dette technique (visibilit√© et priorisation)
- Collaborer avec l'Agents Engineer pour calibrer Agent Architecture
- Coacher les PE sur sujets techniques complexes

**Le r√¥le dans les d√©cisions techniques :**

```
D√©cisions Strat√©giques (Architecture globale, choix stack)
‚Üí Tech Lead D√âCIDE avec input √©quipe

D√©cisions Tactiques (Patterns, libraries, approches)
‚Üí Tech Lead GUIDE, √©quipe d√©cide

D√©cisions Op√©rationnelles (Impl√©mentation sp√©cifique)
‚Üí PE D√âCIDE avec autonomie
```

**Indicateurs de succ√®s :**
- Dette technique : tendance d√©croissante ou stable
- Satisfaction PE sur guidelines : >8/10
- Temps design review : <2h
- D√©cisions architecturales revisit√©es : <10% /an

> üìñ *Voir Annexe B.4 pour les anti-patterns et exemples de design reviews*

---

## Stakeholders et Supporters

### Stakeholders - Porteurs d'Int√©r√™ts

**D√©finition :** Toute entit√© int√©ress√©e par, affect√©e par, ou impactant le produit.

**Types de stakeholders :**
1. **Primaires** : Utilisateurs finaux, Clients, D√©cideurs, √âquipe produit
2. **Secondaires** : Sponsors financiers, Gouvernance, Partenaires, Concurrents
3. **Tertiaires** : L√©gislateurs, Communaut√©, √âcosyst√®me

**Principes de gestion :**
- **Priorisation claire** : Tous les stakeholders ne sont pas √©gaux
- **Engagement intentionnel** : Interactions r√©guli√®res avec prioritaires
- **Feedback syst√©matique** : Boucles courtes de validation
- **Transparence** : Communication claire sur d√©cisions et trade-offs

### Supporters - Facilitateurs de Succ√®s

**D√©finition :** Stakeholders qui facilitent activement le succ√®s de l'√©quipe en cr√©ant les conditions optimales.

**Responsabilit√©s critiques :**
1. **Cr√©er le Climate** : Environnement psychologiquement s√ªr, culture d'exp√©rimentation
2. **Lever les Obstacles** : R√©soudre probl√®mes organisationnels que l'√©quipe ne peut pas r√©soudre
3. **Faciliter l'Acc√®s** : Aux ressources, stakeholders, informations

> üìñ *Voir Annexe B.5 pour les r√¥les typiques de Supporters et anti-patterns*

---

# Les Artefacts Vivants

## Principe Cardinal

Les artefacts AIAD ne sont pas de la bureaucratie. Ce sont des **outils de pens√©e et de communication** qui cr√©ent de l'alignement et r√©duisent l'ambigu√Øt√©.

**Un bon artefact AIAD est :**
- ‚úÖ **Actionnable** : On peut agir √† partir de lui
- ‚úÖ **Vivant** : Il √©volue avec la compr√©hension
- ‚úÖ **Minimal** : Juste assez, pas plus
- ‚úÖ **Collaboratif** : Co-cr√©√©, pas dict√©

## Les 4 Artefacts Essentiels

### 1. Product Requirement Document (PRD)

**Objectif :** Clarifier POURQUOI et QUOI construire avant de se poser la question du COMMENT.

**Sections cl√©s :**
- **Contexte et Probl√®me** : Quel probl√®me ? Pour qui ? Pourquoi maintenant ?
- **Success Criteria (Outcome Criteria)** : M√©triques mesurables et observables
- **Personas et Use Cases** : Profils utilisateurs et sc√©narios d'usage
- **Hors P√©rim√®tre** : Ce que nous NE faisons PAS (volontairement)
- **Trade-offs et D√©cisions** : D√©cisions majeures prises et alternatives √©cart√©es
- **D√©pendances et Risques** : Pr√©requis et risques identifi√©s

**Bonnes pratiques :**
1. Commencer par le probl√®me, pas par la solution
2. Outcome-driven : D√©finir success criteria mesurables avant de construire
3. Collaboratif : R√©diger avec l'√©quipe, pas pour l'√©quipe
4. It√©ratif : Le PRD √©volue avec la compr√©hension
5. Visuel : Int√©grer wireframes, flows quand pertinent

**Anti-patterns :**
- üö´ PRD fleuve de 50 pages que personne ne lira
- üö´ PRD dictatorial avec solution impos√©e
- üö´ PRD vague : "Am√©liorer l'exp√©rience utilisateur"
- üö´ PRD statique jamais mis √† jour

> üìñ *Voir Annexe A.1 pour le template complet et exemples*

---

### 2. Document ARCHITECTURE

**Objectif :** D√©finir les standards techniques que les agents IA et les PE doivent respecter.

**Sections cl√©s :**
- **Principes Architecturaux** : 5 principes non-n√©gociables
- **Vue d'Ensemble** : Architecture high-level avec justification
- **Stack Technique** : Technologies, versions, justifications
- **Structure du Projet** : Organisation dossiers et modules
- **Conventions de Code** : Nommage, formatage, imports
- **Patterns et Bonnes Pratiques** : Design patterns avec exemples
- **S√©curit√©** : Principes et pratiques obligatoires
- **Performance** : Budgets de performance et strat√©gies
- **Qualit√© et Dette Technique** : Definition of Output Done, gestion dette
- **ADR (Architecture Decision Records)** : D√©cisions majeures document√©es

**Bonnes pratiques :**
1. √âvolutif, pas fig√© : L'architecture √©volue avec le produit
2. Justifi√© : Chaque choix a une rationale explicite
3. Pragmatique : Pas d'over-engineering, YAGNI
4. Communicable : Diagrammes visuels, pas que du texte
5. Actionnable : Les PE peuvent s'y r√©f√©rer quotidiennement

**Anti-patterns :**
- üö´ Ivory tower architecture : D√©cider sans conna√Ætre la r√©alit√©
- üö´ CV-driven development : Choisir des technos pour le CV
- üö´ Documentation obsol√®te qui ne refl√®te pas la r√©alit√©
- üö´ Complexit√© pr√©matur√©e pour des probl√®mes hypoth√©tiques

> üìñ *Voir Annexe A.2 pour le template complet et exemples d'ADR*

---

### 3. AGENT-GUIDE (ex. CLAUDE.md)

**Objectif :** Fournir le contexte optimal aux agents IA pour qu'ils g√©n√®rent du code de qualit√© align√© avec les standards de l'√©quipe.

**Principe cardinal :** Un agent sans contexte g√©n√®re du code g√©n√©rique. Un agent avec un contexte riche g√©n√®re du code professionnel.

**Sections cl√©s :**
- **Identit√© du Projet** : Nom, description, domaine m√©tier, mission
- **Documentation de R√©f√©rence** : Liens vers PRD, ARCHITECTURE, SPECs
- **Stack Technique** : R√©sum√© des technologies utilis√©es
- **R√®gles Absolues** : TOUJOURS (obligations) et JAMAIS (interdictions)
- **Conventions de Code** : Nommage, organisation imports, structure composants
- **Vocabulaire M√©tier** : Termes sp√©cifiques au domaine avec d√©finitions
- **Configuration des Agents Sp√©cialis√©s** : R√®gles sp√©cifiques par agent
- **Patterns de D√©veloppement** : Approches favoris√©es avec exemples
- **Anti-Patterns** : Ce qu'il faut √©viter avec exemples
- **Notes d'Apprentissage** : Learnings mis √† jour continuellement

**Bonnes pratiques :**
1. Concret et actionnable : Exemples de code, pas juste principes abstraits
2. √âvolutif : Section "Notes d'Apprentissage" mise √† jour continuellement
3. Contextuel : Vocabulaire m√©tier sp√©cifique au domaine
4. √âquilibr√© : Ne pas tomber dans l'exc√®s (100+ r√®gles = aucune r√®gle)
5. Vivant : Review mensuelle minimum pour synchroniser avec la r√©alit√©

**Anti-patterns :**
- üö´ Guide encyclop√©dique de 50 pages que personne ne lit
- üö´ Guide obsol√®te √©crit au d√©but puis jamais mis √† jour
- üö´ Guide vague : "√âcrire du bon code" (pas actionnable)
- üö´ Guide dictatorial avec trop de r√®gles rigides

> üìñ *Voir Annexe A.3 pour le template complet avec exemples de r√®gles*

---

### 4. Document SPECS (Sp√©cifications Techniques)

**Objectif :** Bridge entre l'intention m√©tier (PRD) et l'impl√©mentation concr√®te par les agents IA.

**Principe cardinal :** Une SPEC de qualit√© permet √† un agent IA de g√©n√©rer 80%+ du code correct du premier coup.

**Sections cl√©s :**
- **Contexte** : R√©f√©rence User Story, objectif, outcome attendu
- **P√©rim√®tre** : In Scope / Out of Scope explicites
- **Fichiers Impact√©s** : √Ä cr√©er / √Ä modifier
- **Interface Technique** : API endpoints, types, sch√©mas DB
- **Comportement D√©taill√©** : Flow nominal et cas limites
- **Validation Rules** : R√®gles de validation avec sch√©mas
- **Business Rules** : R√®gles m√©tier √† appliquer
- **Tests Attendus** : Sc√©narios de test √† impl√©menter
- **Exemples d'Usage** : Exemples concrets requ√™te/r√©ponse
- **Outcome Criteria** : Comment mesurer le succ√®s (si applicable)
- **D√©pendances** : Pr√©-requis et impacts downstream
- **Definition of Output Done Checklist** : Crit√®res de "Done"

**Crit√®res d'une SPEC de qualit√© :**

| Crit√®re | Bon Exemple | Mauvais Exemple |
|---------|-------------|-----------------|
| **Atomicit√©** | "Impl√©menter cr√©ation t√¢che via API" | "Faire module gestion de t√¢ches" |
| **Pr√©cision** | "Retourner 400 si title vide ou >200 chars" | "G√©rer les erreurs" |
| **Testabilit√©** | "Accepter 'test@example.com', rejeter 'invalid'" | "Tester la validation" |
| **Compl√©tude** | Inclut types, validation, edge cases, tests | "Cr√©er endpoint POST" |

**Anti-patterns :**
- üö´ SPEC vague : "Am√©liorer la performance" (non actionnable)
- üö´ SPEC tentaculaire : 20 fonctionnalit√©s dans une SPEC
- üö´ SPEC code : √âcrire le code directement dans la SPEC
- üö´ SPEC obsol√®te jamais mise √† jour avec les learnings

> üìñ *Voir Annexe A.4 pour le template complet et exemples de SPECs*

---

## Definitions of Done

### Definition of Output Done (DoOD)

**Objectif :** Standard de qualit√© uniforme et non-n√©gociable pour qu'un incr√©ment soit consid√©r√© comme "Done" et livrable.

**Principe :** Une fonctionnalit√© n'est "Done" que si TOUS les crit√®res sont satisfaits. Pas d'exception. Pas de "Done √† 90%".

**Cat√©gories de crit√®res :**

**Crit√®res Techniques :**
- Code Quality (conventions, linting, types, complexit√©, commentaires)
- Testing (couverture, tous tests passent, edge cases, pas de flaky tests)
- Security (scan pass√©, pas de secrets, validation inputs, gestion erreurs)
- Performance (budgets respect√©s, queries optimis√©es, monitoring)

**Crit√®res Fonctionnels :**
- Conformit√© (spec respect√©e, acceptance criteria valid√©s)
- Documentation (API, README, CHANGELOG)

**Crit√®res de D√©ploiement :**
- CI/CD (build r√©ussit, d√©ploy√© staging, smoke tests, rollback plan)
- Review (code review, QA validation, PM validation si pertinent)

**Crit√®res de Qualit√© Long-Terme :**
- Maintenabilit√© (pas de dette ou dette document√©e, architecture coh√©rente)

**Ce qui N'est PAS "Done" :**
- ‚ùå "Le code compile"
- ‚ùå "√áa marche sur ma machine"
- ‚ùå "Les tests passent localement"
- ‚ùå "Done √† 90%"
- ‚ùå "On testera/documentera plus tard"

> üìñ *Voir Annexe A.5 pour la checklist compl√®te et exemples*

---

### Definition of Outcome Done (DoOuD)

**Objectif :** D√©finir comment mesurer si la valeur attendue a √©t√© r√©alis√©e pour les stakeholders.

**Principe :** L'output (code livr√©) n'est que le moyen. L'outcome (valeur r√©alis√©e) est le but.

**Cat√©gories de m√©triques :**

**User Outcomes :**
- Satisfaction utilisateur (NPS, CSAT)
- Adoption fonctionnalit√©
- Time to Value
- Retention

**Business Outcomes :**
- Impact business (MRR, conversions, etc.)
- Efficacit√© op√©rationnelle
- R√©duction co√ªts

**Learning Outcomes :**
- Hypoth√®ses valid√©es/invalid√©es
- Insights utilisateur d√©couverts
- Learnings techniques

**Process de mesure :**
1. D√©finir outcomes AVANT de construire
2. Mesurer √† des jalons d√©finis (1 sem, 1 mois, 3 mois)
3. Comparer attendu vs. r√©alis√©
4. D√©cider : Continuer / It√©rer / Sunset
5. Documenter learnings

> üìñ *Voir Annexe A.6 pour le template complet et exemples de m√©triques*

---

# Les Boucles It√©ratives Continues

## Philosophie : Au-del√† des C√©r√©monies

**La rigidit√© tue l'adaptabilit√©.**

AIAD abandonne compl√®tement les Sprints Scrum au profit de **boucles it√©ratives fluides**.

**Caract√©ristiques des boucles :**
- **Flux continu** : D√®s qu'une fonctionnalit√© est int√©gr√©e, la prochaine d√©marre
- **Dur√©e variable** : Une fonctionnalit√© peut prendre 2h ou 3 jours selon sa complexit√©
- **Priorit√© dynamique** : La prochaine fonctionnalit√© peut changer en fonction du feedback
- **Focus absolu** : Une seule fonctionnalit√© √† la fois par PE (pas de multitasking)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                          ‚îÇ
‚îÇ   PLANIFIER ‚Üí IMPL√âMENTER ‚Üí VALIDER ‚Üí INT√âGRER          ‚îÇ
‚îÇ       ‚Üë                                          ‚Üì        ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ   Feedback utilisateur ‚Üí Ajustement priorit√©s           ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Phase d'Initialisation (Une fois par produit)

**Dur√©e totale :** 4-7 jours  
**Fr√©quence :** Une seule fois au d√©but (ou √† chaque pivot majeur)

**Objectifs globaux :**
1. √âtablir la vision produit et le Product Goal initial
2. D√©finir l'architecture technique et le stack
3. Configurer l'environnement de d√©veloppement
4. Initialiser l'√©cosyst√®me d'agents IA
5. Pr√©parer la premi√®re fonctionnalit√©

**Livrables attendus :**
- [ ] Product Vision et Product Goal document√©s
- [ ] PRD initial cr√©√©
- [ ] Document ARCHITECTURE complet
- [ ] AGENT-GUIDE (CLAUDE.md) complet
- [ ] Definition of Output Done (DoOD) d√©fini
- [ ] Definition of Outcome Done (DoOuD) d√©fini
- [ ] Repository Git initialis√© avec CI/CD
- [ ] Environnements staging/production cr√©√©s
- [ ] Agents sp√©cialis√©s s√©lectionn√©s et configur√©s
- [ ] Premi√®re SPEC pr√™te pour impl√©mentation

> üìñ *Voir Annexe C.1 pour le process d√©taill√© jour par jour*

---

## Les 4 Boucles Continues

### Boucle 1 : PLANIFIER LA FONCTIONNALIT√â

**D√©clencheur :** Fonctionnalit√© pr√©c√©dente int√©gr√©e OU nouvelle priorit√© critique

**Participants :** PM + PE (+ QA si complexe, + Tech Lead si impacte architecture)

**Dur√©e :** 30 min - 4h (selon complexit√©)

**Objectif :** Transformer une intention m√©tier en SPEC actionnable pour les agents IA

**√âtapes cl√©s :**
1. PM pr√©sente la prochaine priorit√© (contexte, user story, outcomes)
2. PE questionne et clarifie (cas limites, d√©pendances, risques, complexit√©)
3. D√©cision de d√©composition (simple/complexe/tr√®s complexe)
4. R√©daction collaborative de la SPEC
5. Validation finale

**Livrables :**
- [ ] SPEC d√©taill√©e dans `/docs/specs/SPEC-XXX.md`
- [ ] Outcome Criteria d√©finis (si feature majeure)
- [ ] Compr√©hension partag√©e de l'objectif

**Indicateur de qualit√© :**
- ‚úÖ Un agent IA peut comprendre et impl√©menter √† partir de cette SPEC seule
- ‚úÖ Les tests attendus sont clairs et actionnables
- ‚úÖ Tous les cas limites sont document√©s

> üìñ *Voir Annexe C.2 pour le process d√©taill√© et exemples*

---

### Boucle 2 : IMPL√âMENTER

**D√©clencheur :** SPEC valid√©e et pr√™te

**Participants :** PE + Agents IA (+ Agents Engineer si probl√®me)

**Dur√©e :** Variable (2h - 3 jours)

**Objectif :** Transformer la SPEC en code fonctionnel de qualit√© professionnelle

**√âtapes cl√©s :**
1. Pr√©paration du contexte (/clear, lecture SPEC/PRD/ARCHITECTURE/AGENT-GUIDE)
2. Orchestration de l'impl√©mentation (prompt structur√©, validation du plan)
3. Validation continue (compilation, linting, conformit√© SPEC, types)
4. G√©n√©ration des tests (Agent Quality, v√©rification couverture)
5. Corrections it√©ratives (max 3 it√©rations)
6. Finalisation (tous tests passent, DoOD respect√©, commit local)

**Livrables :**
- [ ] Code fonctionnel respectant le Definition of Output Done
- [ ] Tests automatis√©s passant (couverture >80%)
- [ ] Documentation mise √† jour si n√©cessaire
- [ ] Commit pr√™t (pas encore pouss√©)

**Indicateurs de qualit√© :**
- ‚úÖ First-time success >70%
- ‚úÖ Ratio code g√©n√©r√© / manuel : >80/20
- ‚úÖ Couverture de tests : >80% backend, >70% frontend
- ‚úÖ Aucun warning linter

**Pratiques cl√©s d'orchestration :**
1. Contexte optimal : Toujours r√©f√©rencer @SPEC, @CLAUDE.md, @ARCHITECTURE.md
2. Validation du plan : Demander le plan AVANT de coder
3. It√©ration progressive : Impl√©menter par morceaux si complexe
4. Utilisation agents sp√©cialis√©s : Quality, Security, Architecture
5. Mise √† jour AGENT-GUIDE : Documenter learnings au fil de l'eau

> üìñ *Voir Annexe C.3 pour le workflow d√©taill√© et prompt patterns*

---

### Boucle 3 : VALIDER

**D√©clencheur :** Code impl√©ment√© et tests passent localement

**Participants :** QA + PE (+ PM si feature critique)

**Dur√©e :** 1h - 4h (selon criticit√©)

**Objectif :** S'assurer que la fonctionnalit√© r√©pond aux attentes m√©tier ET aux standards de qualit√©

**√âtapes cl√©s :**
1. Validation Technique (PE) : Tests CI, couverture, linting, DoOD
2. Validation Fonctionnelle (QA) : Deploy test, tests fonctionnels, acceptance criteria
3. Validation Utilisabilit√© (QA + PM) : Interface, UX, accessibilit√©, performance
4. Validation Agents Sp√©cialis√©s : Security, Architecture, Quality, Performance
5. Validation M√©tier (PM si majeure) : D√©mo, v√©rification intention, outcomes
6. D√©cision : VALID√â / CORRECTIONS MINEURES / REJET

**Livrables :**
- [ ] Rapport de validation QA
- [ ] Liste de corrections mineures (si applicable)
- [ ] Validation PM (si feature majeure)
- [ ] Feu vert pour int√©gration

**Indicateurs de qualit√© :**
- ‚úÖ Taux de validation au premier essai : >70%
- ‚úÖ Temps moyen de validation : <2h
- ‚úÖ Bugs critiques d√©tect√©s : 0
- ‚úÖ Bugs mineurs : <3 par feature

> üìñ *Voir Annexe C.4 pour le template de rapport QA et process d√©taill√©*

---

### Boucle 4 : INT√âGRER & SAUVEGARDER

**D√©clencheur :** Validation OK (tous les feux verts)

**Participants :** PE (+ DevOps si probl√®me de d√©ploiement)

**Dur√©e :** 30min - 2h

**Objectif :** Int√©grer le code dans la branche principale, d√©ployer, et pr√©parer la prochaine it√©ration

**√âtapes cl√©s :**
1. Revue de Code (self ou peer selon criticit√©)
2. Pr√©paration au Merge (pull main, r√©solution conflits, tests)
3. Push et Merge (PR, CI/CD, auto-merge ou manuel)
4. D√©ploiement (auto-deploy staging, smoke tests, release production)
5. V√©rification Post-D√©ploiement (monitoring, logs, m√©triques)
6. Documentation et Tra√ßabilit√© (commit structur√©, CHANGELOG, tag)
7. Pr√©paration Prochaine It√©ration (/clear, update AGENT-GUIDE, fermeture ticket)

**Livrables :**
- [ ] Code merg√© dans branche principale
- [ ] D√©ploy√© en staging (minimum)
- [ ] Id√©alement : d√©ploy√© en production (livraison continue)
- [ ] CHANGELOG mis √† jour (si release)
- [ ] Contexte agent nettoy√©
- [ ] AGENT-GUIDE mis √† jour (si learnings)

**Strat√©gies de D√©ploiement :**

| Strat√©gie | Quand | Risque | Vitesse feedback |
|-----------|-------|--------|------------------|
| **Continuous Deployment** | Features non-critiques | Bas | Maximum |
| **Staged Rollout** | Features majeures | Moyen | Rapide |
| **Feature Flags** | Exp√©rimentales, A/B | Tr√®s bas | Maximum |
| **Manual Release** | Critiques, compliance | Tr√®s bas | Lent |

**Recommandation AIAD :** Viser Continuous Deployment avec Feature Flags.

**Indicateurs de qualit√© :**
- ‚úÖ Temps merge √† production : <1h (id√©alement <15min)
- ‚úÖ Taux de rollback : <5%
- ‚úÖ Downtime lors d√©ploiements : 0
- ‚úÖ MTTR : <15min

> üìñ *Voir Annexe C.5 pour Conventional Commits et strat√©gies de d√©ploiement*

---

# Synchronisations Intentionnelles

## Principes Transversaux

Les synchronisations remplacent les c√©r√©monies Scrum rigides. Elles sont :

1. **Intentionnelles** : Objectif clair et participants pertinents
2. **Timebox√©es** : Dur√©e maximale d√©finie et RESPECT√âE
3. **Actionnables** : G√©n√®rent des d√©cisions concr√®tes et actions assign√©es
4. **Flexibles** : Fr√©quence et format s'adaptent au contexte
5. **Orient√©es Valeur** : Focus sur valeur, outcomes, apprentissage
6. **Document√©es** : Notes disponibles pour toute l'√©quipe
7. **Am√©lior√©es Continuellement** : Feedback r√©gulier sur leur utilit√©

---

## Les 5 Synchronisations Cl√©s

### Sync 1 : Alignment Strat√©gique

**Objectif :** S'assurer que l'√©quipe reste align√©e avec la strat√©gie produit et adapter le Product Goal si n√©cessaire.

**Fr√©quence :** Mensuel ou Bi-Mensuel (ou quand Product Goal atteint)

**Participants :** PM + PE + Tech Lead + QA + Stakeholders cl√©s + Supporters

**Dur√©e :** 1.5 - 2h

**Agenda principal :**
1. Review des Outcomes (30min) : Outcomes atteints, learnings, side effects
2. Review du Product Goal (20min) : Pertinence, adaptation, prochain goal
3. Priorisation Product Backlog (40min) : Prochaines priorit√©s, ce qu'on d√©cide de NE PAS faire
4. Feedback Supporters (20min) : Obstacles organisationnels, actions
5. Actions et D√©cisions (10min) : R√©sum√©, Product Goal valid√©, actions assign√©es

**Livrables :**
- [ ] Product Goal valid√© ou adapt√©
- [ ] Product Backlog √† jour et prioris√©
- [ ] Liste d'actions Supporters
- [ ] D√©cisions strat√©giques document√©es

**Indicateurs de succ√®s :**
- Alignement √©quipe sur Product Goal : 100%
- Clart√© sur 5 prochaines priorit√©s : Cristalline
- Actions Supporters compl√©t√©es : >80%

> üìñ *Voir Annexe D.1 pour le template de notes et exemples*

---

### Sync 2 : Demo & Feedback Utilisateurs

**Objectif :** Obtenir du feedback direct et rapide des utilisateurs/clients/stakeholders sur les fonctionnalit√©s livr√©es.

**Fr√©quence :** Hebdomadaire OU apr√®s chaque feature majeure

**Participants :** PM + PE + Utilisateurs/Clients/Stakeholders concern√©s

**Dur√©e :** 30min - 1h

**Agenda principal :**
1. D√©monstration (15-20min) : PE montre fonctionnalit√©s, focus usage r√©el
2. Feedback Qualitatif (20-30min) : Questions ouvertes, discussion
3. Analyse des Donn√©es (10min) : M√©triques d'usage si disponibles
4. Adaptation Product Backlog (10min) : Nouvelles stories, repriorisation

**Livrables :**
- [ ] Feedback utilisateur document√©
- [ ] Nouvelles user stories ajout√©es (si pertinent)
- [ ] Product Backlog reprioris√© si n√©cessaire
- [ ] D√©cisions d'it√©ration ou pivot document√©es

**Indicateurs de succ√®s :**
- Feedback actionnable obtenu : >3 insights par session
- Satisfaction utilisateur sur features : >8/10
- Taux participation stakeholders : >70%

> üìñ *Voir Annexe D.2 pour le template de notes et questions type*

---

### Sync 3 : Tech Review

**Objectif :** Assurer coh√©rence technique et excellence architecturale, g√©rer dette technique, optimiser √©cosyst√®me d'agents.

**Fr√©quence :** Mensuel OU apr√®s changements architecturaux majeurs

**Participants :** Tech Lead + PE + Agents Engineer (+ QA si pertinent)

**Dur√©e :** 1 - 2h

**Agenda principal :**
1. Review de l'Architecture (30min) : ARCHITECTURE √† jour, d√©rives, adaptations
2. Review Dette Technique (30min) : Niveau dette, priorit√©s rem√©diation, pr√©vention
3. Review √âcosyst√®me Agents (30min) : Pertinence agents, performance, ajouts/retraits
4. Partage Pratiques et Learnings (20min) : Nouveaux patterns, anti-patterns
5. Actions et D√©cisions (10min) : R√©sum√© d√©cisions, plan rem√©diation

**Livrables :**
- [ ] Document ARCHITECTURE mis √† jour (si changements)
- [ ] Plan de rem√©diation dette technique
- [ ] Catalogue d'agents adapt√©
- [ ] AGENT-GUIDE mis √† jour
- [ ] ADR pour d√©cisions majeures

**Indicateurs de succ√®s :**
- Dette technique : tendance d√©croissante ou stable
- Performance agents : am√©lioration continue
- AGENT-GUIDE : mis √† jour mensuellement minimum
- Participation PE : >80%

> üìñ *Voir Annexe D.3 pour le template de notes et crit√®res de priorisation dette*

---

### Sync 4 : Retrospective d'√âquipe

**Objectif :** Am√©lioration continue de l'efficacit√©, du bien-√™tre et de la collaboration de l'√©quipe.

**Fr√©quence :** Hebdomadaire ou Bi-Hebdomadaire

**Participants :** PE + PM + Agents Engineer + QA + Tech Lead

**Dur√©e :** 45min - 1h

**Agenda principal :**
1. R√©trospective Classique (30min) : Start / Stop / Continue (ou autre format)
2. R√©trospective IA Sp√©cifique (20min) : Prompts efficaces, erreurs r√©currentes agents, AGENT-GUIDE
3. Am√©lioration Workflow (10min) : Goulots, collaboration, synchronisations
4. Actions et Engagement (10min) : 1-3 actions max, owners, deadlines

**Formats de Facilitation (√† varier) :**
- Start / Stop / Continue
- Mad / Sad / Glad
- 4Ls : Liked / Learned / Lacked / Longed For
- Sailboat (visuel)
- Timeline

**Livrables :**
- [ ] Actions d'am√©lioration (1-3 max)
- [ ] AGENT-GUIDE mis √† jour avec learnings
- [ ] Engagement collectif sur actions

**Indicateurs de succ√®s :**
- Participation √©quipe : 100%
- Actions compl√©t√©es (review retro suivante) : >80%
- Satisfaction √©quipe : tendance croissante ou stable >7/10
- Am√©lioration continue : ‚â•1 action impl√©ment√©e par retro

> üìñ *Voir Annexe D.4 pour le template de notes et formats de facilitation*

---

### Sync 5 : Standup Quotidien (OPTIONNEL)

**Objectif :** Synchronisation rapide quotidienne pour aligner travail en cours et identifier blocages.

**Fr√©quence :** Quotidien (si l'√©quipe le souhaite)

**Participants :** PE (+ autres r√¥les si souhait√©)

**Dur√©e :** 5 - 15 minutes MAX

**Format A : Synchrone**
Chaque membre partage (1-2min max) :
1. Sur quoi je travaille actuellement
2. Ce que je pr√©vois de faire aujourd'hui
3. Blocages √©ventuels

**Format B : Asynchrone** (recommand√© pour √©quipes distribu√©es)
Via Slack/Teams, chaque matin :
- **Hier :** [Ce que j'ai fait]
- **Aujourd'hui :** [Ce que je pr√©vois]
- **Blocages :** [Aucun / Description]

**Indicateurs de succ√®s :**
- Participation : >90%
- Dur√©e respect√©e : <15min
- Blocages r√©solus dans la journ√©e : >80%

**Anti-patterns :**
- üö´ Standup de 45min qui devient r√©union de status
- üö´ D√©bats techniques pendant le standup
- üö´ Micro-management d√©guis√©
- üö´ Obligation rigide sans valeur ajout√©e

> üìñ *Voir Annexe D.5 pour exemples de standup efficaces*

---

# M√©triques et Am√©lioration Continue

## Principe Cardinal

**"Ce qui n'est pas mesur√© ne peut pas √™tre am√©lior√©."** - Peter Drucker

AIAD adopte une approche **data-informed** (pas data-driven) : les m√©triques informent les d√©cisions, mais ne les dictent pas. Le contexte et le jugement humain restent essentiels.

---

## Les 5 Cat√©gories de M√©triques

### 1. M√©triques de Productivit√©

**Objectif :** Mesurer la capacit√© de l'√©quipe √† livrer de la valeur rapidement.

| M√©trique | Cible | Fr√©quence |
|----------|-------|-----------|
| **Cycle Time** (PLANIFIER ‚Üí INT√âGRER) | <3 jours | Hebdomadaire |
| **Lead Time** (Id√©e ‚Üí Production) | <2 semaines | Hebdomadaire |
| **Throughput** (Fonctionnalit√©s livr√©es) | Stable ou ‚¨ÜÔ∏è | Hebdomadaire |
| **Release Frequency** | Quotidien (id√©al) | Hebdomadaire |
| **Deployment Success Rate** | >95% | Hebdomadaire |

**Analyse :**
- Cycle Time ‚¨ÜÔ∏è ‚Üí Fonctionnalit√©s trop complexes ? Probl√®mes agents ?
- Lead Time stagnant ‚Üí Goulots dans les boucles ?
- Throughput ‚¨áÔ∏è ‚Üí Qualit√© SPECs ? Motivation √©quipe ?

---

### 2. M√©triques de Qualit√©

**Objectif :** Mesurer la qualit√© du code et la robustesse du produit.

| M√©trique | Cible | Fr√©quence |
|----------|-------|-----------|
| **Couverture de Tests** | >80% backend, >70% frontend | Hebdomadaire |
| **Bugs en Production** | Tendance ‚¨áÔ∏è (-20% /trimestre) | Hebdomadaire |
| **Mean Time To Detect (MTTD)** | <24h | Mensuel |
| **Mean Time To Repair (MTTR)** | <4h | Mensuel |
| **Dette Technique** | Stable ou ‚¨áÔ∏è | Mensuel |
| **First-Time Success Rate** | >70% | Hebdomadaire |

**Analyse :**
- Couverture <80% ‚Üí Agent Quality mal configur√© ?
- Bugs ‚¨ÜÔ∏è ‚Üí DoOD pas respect√© ? Validation QA insuffisante ?
- MTTR √©lev√© ‚Üí Monitoring insuffisant ? Architecture coupl√©e ?

---

### 3. M√©triques d'Efficacit√© IA

**Objectif :** Mesurer la performance de l'√©cosyst√®me d'agents IA.

| M√©trique | Cible | Fr√©quence |
|----------|-------|-----------|
| **Taux d'Adoption Agents** | >90% | Hebdomadaire |
| **First-Time Success Rate (Agents)** | >70% | Hebdomadaire |
| **Ratio Code G√©n√©r√© / Manuel** | >80/20 | Hebdomadaire |
| **It√©rations Moyennes par Feature** | <3 | Hebdomadaire |
| **Taux de Faux Positifs (Agents)** | <20% | Mensuel |
| **Temps R√©solution Probl√®mes Agents** | <2h | Mensuel |
| **Satisfaction PE sur √âcosyst√®me** | >8/10 | Mensuel |

**Analyse :**
- Adoption <90% ‚Üí Agents pas performants ? R√©sistance culturelle ?
- First-Time Success <70% ‚Üí AGENT-GUIDE obsol√®te ? SPECs mal r√©dig√©es ?
- Faux positifs >20% ‚Üí Agents trop sensibles, besoin tuning

---

### 4. M√©triques d'Outcomes

**Objectif :** Mesurer la valeur r√©elle livr√©e aux stakeholders.

| M√©trique | Cible | Fr√©quence |
|----------|-------|-----------|
| **Atteinte Outcome Criteria** | >70% | Mensuel |
| **Satisfaction Utilisateur (NPS, CSAT)** | >8/10 | Mensuel |
| **Adoption Fonctionnalit√©** | >60% en 1 mois | Par feature |
| **Time to Value** | <5 min (selon produit) | Mensuel |
| **Retention Rate** | >80% (selon produit) | Mensuel |
| **Business Impact** | Variable | Mensuel |

**Analyse :**
- Atteinte outcomes <70% ‚Üí Probl√®me discovery ? Hypoth√®ses invalides ?
- Satisfaction <8 ‚Üí Features ne r√©solvent pas le vrai probl√®me ?
- Adoption faible ‚Üí Probl√®me go-to-market ? Feature pas utile ?

---

### 5. M√©triques d'√âquipe

**Objectif :** Mesurer le bien-√™tre et l'engagement de l'√©quipe.

| M√©trique | Cible | Fr√©quence |
|----------|-------|-----------|
| **Satisfaction √âquipe** | >7/10 | Hebdomadaire (pulse) |
| **Psychological Safety** | >8/10 | Mensuel |
| **Temps en Flow** | >4h/jour | Hebdomadaire |
| **Turnover** | <10% /an | Annuel |
| **Sick Days** | Baseline stable | Mensuel |

**Analyse :**
- Satisfaction <7 ‚Üí Probl√®mes management ? Surcharge ? Manque autonomie ?
- Temps en flow <4h ‚Üí Trop d'interruptions ? Trop de syncs ?
- Turnover √©lev√© ‚Üí Burnout ? Manque perspectives ?

---

## Dashboard de Suivi Recommand√©

**Principe :** Un dashboard AIAD doit √™tre actionnable, pas juste informatif. Chaque m√©trique doit pointer vers une action possible.

### Vue Hebdomadaire (pour l'√©quipe)

**Sections :**
1. **Productivit√©** : Cycle Time, Throughput, Release Frequency
2. **Qualit√©** : Couverture Tests, Bugs Production, First-Time Success
3. **Efficacit√© IA** : Adoption Agents, First-Time Success Agents, Ratio G√©n√©r√©/Manuel
4. **√âquipe** : Satisfaction, Temps en Flow

### Vue Mensuelle (pour PM + Stakeholders)

**Sections :**
1. **Outcomes** : Atteinte Criteria, NPS, Adoption, Business Impact
2. **Lead Time** : √âvolution et objectif
3. **Dette Technique** : Niveau et tendance
4. **Top 3 Actions N√©cessaires**

> üìñ *Voir Annexe E.1 pour exemples de dashboards complets*

---

## Processus d'Am√©lioration Continue

**Framework :** PDCA (Plan-Do-Check-Act) adapt√© √† AIAD

### Le Cycle PDCA

```
1. PLAN (Planifier l'am√©lioration)
   ‚îú‚îÄ Identifier un probl√®me via les m√©triques
   ‚îú‚îÄ Analyser la cause racine (5 Why's, Fishbone)
   ‚îú‚îÄ D√©finir une hypoth√®se d'am√©lioration
   ‚îî‚îÄ D√©finir comment mesurer le succ√®s

2. DO (Exp√©rimenter la solution)
   ‚îú‚îÄ Impl√©menter le changement (petite √©chelle d'abord)
   ‚îú‚îÄ Documenter le changement
   ‚îî‚îÄ Mesurer les r√©sultats

3. CHECK (V√©rifier l'impact)
   ‚îú‚îÄ Analyser les donn√©es avant/apr√®s
   ‚îú‚îÄ Le probl√®me est-il r√©solu ?
   ‚îú‚îÄ Y a-t-il des effets de bord ?
   ‚îî‚îÄ L'hypoth√®se est-elle valid√©e ?

4. ACT (Agir selon les r√©sultats)
   ‚îú‚îÄ Si succ√®s ‚Üí Standardiser (update docs)
   ‚îú‚îÄ Si √©chec ‚Üí Apprendre et essayer autre chose
   ‚îî‚îÄ Communiquer les learnings
```

### Cadence d'Am√©lioration Continue

| Fr√©quence | Activit√© | Responsable |
|-----------|----------|-------------|
| **Quotidien** | Monitoring m√©triques temps r√©el | Automatique (alertes) |
| **Hebdomadaire** | Review m√©triques √©quipe (Retro) | √âquipe |
| **Mensuel** | Review m√©triques outcomes (Alignment) | PM + Stakeholders |
| **Trimestriel** | Review framework AIAD lui-m√™me | √âquipe + Supporters |

---

## Am√©lioration Continue du Framework AIAD

**Principe m√©ta :** AIAD v1.3 n'est pas grav√© dans le marbre. Le framework lui-m√™me doit √™tre am√©lior√© continuellement.

**Questions √† se poser (trimestriellement) :**

1. **Les boucles it√©ratives sont-elles fluides ?**
   - Frictions ou goulots ?
   - Faut-il ajouter/retirer/modifier des √©tapes ?

2. **Les synchronisations sont-elles utiles ?**
   - Apportent-elles de la valeur ?
   - Faut-il adapter fr√©quence ou format ?

3. **Les artefacts sont-ils vivants et utiles ?**
   - PRD, ARCHITECTURE, AGENT-GUIDE √† jour ?
   - Sont-ils utilis√©s quotidiennement ?

4. **L'√©cosyst√®me d'agents est-il optimal ?**
   - Les agents apportent-ils 80%+ de valeur ?
   - Nouveaux agents √† explorer ?

5. **Les m√©triques sont-elles actionnables ?**
   - Informent-elles vraiment les d√©cisions ?
   - Vanity metrics √† retirer ?

6. **L'√©quipe est-elle √©panouie ?**
   - Satisfaction >7/10 ?
   - Turnover acceptable ?
   - √âquilibre vie pro/perso respect√© ?

> üìñ *Voir Annexe E.2 pour le template de revue trimestrielle*

---

# Annexes

**Note :** Les annexes d√©taill√©es seront d√©velopp√©es dans une version ult√©rieure. Elles incluront :

## Annexe A : Templates et Structures
- A.1 Template PRD complet
- A.2 Template ARCHITECTURE complet
- A.3 Template AGENT-GUIDE complet
- A.4 Template SPECS complet
- A.5 Template DoOD avec checklist
- A.6 Template DoOuD avec m√©triques

## Annexe B : D√©tails des Responsabilit√©s
- B.1 Product Manager : Anti-patterns et exemples
- B.2 Product Engineer : Workflow quotidien d√©taill√©
- B.3 QA Engineer : Strat√©gies de test d√©taill√©es
- B.4 Tech Lead : Design reviews et anti-patterns
- B.5 Supporters : R√¥les et anti-patterns

## Annexe C : Processus Op√©rationnels D√©taill√©s
- C.1 Phase d'Initialisation (7 jours d√©taill√©s)
- C.2 Boucle PLANIFIER : Process complet
- C.3 Boucle IMPL√âMENTER : Workflow et prompt patterns
- C.4 Boucle VALIDER : Template rapport QA
- C.5 Boucle INT√âGRER : Conventional Commits et strat√©gies

## Annexe D : Synchronisations D√©taill√©es
- D.1 Alignment Strat√©gique : Template et exemples
- D.2 Demo & Feedback : Questions type
- D.3 Tech Review : Crit√®res priorisation dette
- D.4 Retrospective : Formats de facilitation
- D.5 Standup : Exemples efficaces

## Annexe E : M√©triques et Dashboards
- E.1 Exemples de dashboards complets
- E.2 Template revue trimestrielle AIAD

## Annexe F : Catalogue d'Agents Sp√©cialis√©s
- F.1 Agent Security : Configuration et r√®gles
- F.2 Agent Quality : Configuration et r√®gles
- F.3 Agent Architecture : Configuration et r√®gles
- F.4 Agent Documentation : Configuration et r√®gles
- F.5 Agent Performance : Configuration et r√®gles
- F.6 Agent Code Review : Configuration et r√®gles
- F.7 Autres Agents : Product Management, Refactoring, Migration

## Annexe G : Guides d'Impl√©mentation
- G.1 Configuration environnement (commandes bash)
- G.2 Installation et configuration agents IA
- G.3 Setup CI/CD
- G.4 Configuration permissions
- G.5 Installation MCP et plugins
- G.6 Cr√©ation de SubAgents

## Annexe H : Exemples et Patterns
- H.1 Exemples de prompts efficaces
- H.2 Patterns de code recommand√©s
- H.3 Anti-patterns √† √©viter avec exemples
- H.4 Cas d'usage concrets de SPECs
- H.5 Notes d'apprentissage (learnings)

## Annexe I : Outils et R√©f√©rences
- I.1 Troubleshooting et FAQ
- I.2 Glossaire complet
- I.3 Bibliographie et ressources
- I.4 Communaut√© et support

---

**üéØ Fin du Framework AIAD v1.3**

**La m√©thodologie de r√©f√©rence pour le d√©veloppement produit √† l'√®re des agents IA.**

**Version 1.3 - Janvier 2026**

---

**Prochaines √©tapes pour adopter AIAD :**

1. **Lire le framework** : Comprendre les concepts et principes (30 min)
2. **Planifier l'adoption** : Identifier les quick wins et blockers potentiels (1h)
3. **Former l'√©quipe** : Workshop d'introduction AIAD (4h)
4. **Phase d'initialisation** : Suivre le guide sur 4-7 jours (voir Annexe C.1)
5. **Premiers cycles** : Livrer les 3 premi√®res fonctionnalit√©s en mode AIAD (2-3 semaines)
6. **Premi√®re r√©trospective** : Adapter le framework au contexte (1h)
7. **Am√©lioration continue** : It√©rer sur le framework lui-m√™me (permanent)

**Bon courage dans votre transformation ! üöÄ**